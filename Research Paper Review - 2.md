# AI-SJS

## 논문 리뷰 - 2(2025.09.06)

### 🧠 논문 제목: pen-Vocabulary Object Detection via Scene Graph Discovery
저자: Hengcan Shi, Munawar Hayat, Jianfei Cai 
저널: ACM MM (2023)  
DOI: [https://arxiv.org/abs/2307.03339](https://arxiv.org/abs/2307.03339)

---

### ✨ 연구 배경 및 필요성

기존의 객체 탐지(Object Detection) 모델들은 미리 정해진 고정된 종류(fixed-set)의 객체만 인식할 수 있어, 새로운 종류의 객체를 탐지하려면 모델 전체를 다시 학습해야 하는 한계가 있었습니다. 이를 해결하기 위해, 학습 데이터에 없던 새로운 객체까지 탐지할 수 있는 **개방 어휘 객체 탐지(Open-Vocabulary Object Detection, OV detection)** 기술이 주목받고 있습니다

하지만 기존 OV detection 연구들은 이미지-텍스트 데이터를 활용할 때, '기차', '사람' 같은 개별 객체(명사) 정보에만 집중했습니다. 이로 인해 "트랙 근처에 있는 바위"나 "기차 아래"와 같은 객체 간의 관계 정보(Relational Information)가 가진 풍부한 맥락을 놓치는 문제가 있었습니다. 이 논문은 바로 이 '관계' 정보가 미탐지 객체를 발견하고, 분류하며, 정확한 위치를 찾는 데 결정적인 단서가 될 수 있다는 점에 주목하여, 이를 적극적으로 활용하는 새로운 방법론을 제안합니다

-----

### 🔍 제안 모델: SGDN (Scene-Graph-Based Discovery Network)**

본 논문에서는 객체와 그들 간의 관계를 씬 그래프(Scene Graph)로 모델링하고, 이 그래프 정보를 활용하여 OV detection 성능을 극대화하는 새로운 프레임워크인 **SGDN**을 제안합니다. SGDN은 씬 그래프를 통해 이미지의 맥락적 이해도를 높여, 처음 보는 객체라도 주변 객체와의 관계를 통해 유추하고 탐지해낼 수 있습니다.

-----

### 🎯 핵심 구성 요소
- Scene-Graph-Based Decoder  (SGDecoder)
  → 논문의 핵심 모듈로, 씬 그래프 정보를 객체 피처에 효과적으로 주입하기 위해 새롭게 설계된 SSGA(Sparse Scene-Graph-Guided Attention)를 포함합니다. 이를 통해 객체 탐지, 분류, 위치 특정 전반의 성능을 향상시킵니다

- Scene-Graph-Based Prediction (SGPred)
  → 씬 그래프에 기반한 예측을 수행하는 모듈입니다.

- SGOR (Scene-Graph-Based Offset Regression) 
  → 객체의 위치(Localization)와 씬 그래프 모델링이 서로의 성능을 반복적으로 보강하며 정밀도를 높이는 메커니즘입니다.

- Cross-Modal Learning
  → 씬 그래프를 다리처럼 활용하여 이미지 피처와 텍스트(카테고리) 피처 간의 의미적 일관성을 강화하고, 이를 통해 분류 정확도를 높입니다.
-----

### 🧪 실험 환경 및 성능 요약

OV detection의 표준 벤치마크인 COCO와 LVIS 데이터셋을 이용하여 제로샷(zero-shot) 성능을 평가했습니다. 대규모 데이터셋으로 사전 학습된 모델들과의 공정한 비교를 위해, 동일한 양의 학습 데이터(약 26만 장)로 재학습된 GLIP 모델과 성능을 비교했습니다

| Dataset (Metric) | Model | Novel/Rare | Base/Common | All |
| :--- | :--- | :---: | :---: | :---: |
| **COCO** (AP50) | GLIP [18] (retrain) | 30.7 | 61.0 | 48.6 |
| | **SGDN (Ours)** | **37.5** | **-** | **54.9** |
| **LVIS** (mAP) | GLIP [18] (retrain) | 19.7 | - | 28.3 |
| | **SGDN (Ours)** | **23.6** | - | **31.1** |

📌 기존 SOTA 모델 대비 모든 지표에서 압도적인 성능 향상
특히 학습 데이터에서 보지 못했던 새로운 객체(Novel/Rare Classes)에 대한 탐지 성능(COCO +6.8%p, LVIS +3.9%p)이 크게 향상되어, 제안된 씬 그래프 활용의 효과성을 명확히 입증했습니다.

-----

### 🧪 Ablation Study

각 모듈의 기여도를 분석한 결과, 제안된 모든 요소가 성능 향상에 핵심적인 역할을 하는 것으로 나타났습니다.

- Scene Graph 정보 활용 : 단순 텍스트 정보만 사용했을 때보다 씬 그래프 정보를 추가하자 성능이 2.4%p 상승했습니다[.
- SGDecoder : 제안된 SGDecoder를 적용하자 성능이 추가로 2.3%p 상승하여, 관계 정보를 효과적으로 임베딩하는 능력의 중요성을 보여주었습니다.
- SGPred : 최종 예측단에 SGPred를 적용하자 성능이 2.9%p 추가 상승하며, 위치 예측과 분류 정확도 개선 효과를 증명했습니다.

-----

### 🧠 주요 강점 요약

✅ OV detection 분야에서 최초로 씬 그래프(Scene Graph)를 명시적으로 활용한 연구입니다.
✅ 객체 간의 관계 정보를 통해 처음 보는 객체의 발견(Discovery), 분류, 위치 특정 능력을 크게 향상시켰습니다.
✅ SGOR 메커니즘을 통해 객체 위치 탐지(Localization)와 씬 그래프 추출이 상호 발전하는 구조를 설계했습니다.
✅ 이전 연구들이 수행하지 못했던 OV 씬 그래프 탐지(OV Scene Graph Detection)까지 가능한 최초의 모델입니다.

-----

### ⚠️ 한계 및 향후 과제

  * 복잡성 및 속도: 씬 그래프 생성 및 다중 어텐션 메커니즘으로 인해 모델의 구조가 복잡하며, 실시간 탐지가 필요한 환경에서는 연산 속도 최적화가 필요할 수 있습니다.
  * Parser 의존성: 학습 과정에서 텍스트로부터 관계를 추출하기 위해 외부 언어 파싱 도구(language parsing tools)를 사용하는데, 이 도구의 성능이 전체 모델의 학습 품질에 영향을 줄 수 있습니다

-----

### 💬 한 줄 요약

> "SGDN은 객체 간의 '관계'를 학습하는 씬 그래프를 통해 이미지의 맥락을 깊이 있게 이해함으로써, 처음 보는 객체도 정확하게 찾아내는 차세대 개방 어휘 객체 탐지 프레임워크이다."

-----

### 💭 나의 생각

인공지능학과 학부생으로서 이 논문을 읽으며, 기존 연구의 빈틈을 정확히 찾아내고 이를 창의적인 구조로 해결하는 과정이 매우 인상 깊었습니다. 단순히 개별 객체를 탐지하는 것을 넘어, 객체 간의 '관계'라는 맥락 정보를 모델에 학습시키는 아이디어가 신선했습니다.

특히 데이콘 같은 비전 대회에서 복잡한 이미지 속 특정 객체를 찾아야 할 때, 주변 객체와의 관계를 단서로 활용하면 성능을 크게 높일 수 있을 것 같다는 생각이 들었습니다. SGDecoder나 SGOR 같은 독창적인 모듈을 직접 구현해보면, Transformer 아키텍처와 어텐션 메커니즘에 대한 이해도를 한층 높일 수 있는 좋은 기회가 될 것 같습니다. 이 논문은 단순히 SOTA 성능을 달성한 것을 넘어, '어떻게 AI가 인간처럼 맥락을 이해하게 할 것인가'에 대한 깊은 통찰을 주는 연구였습니다.
